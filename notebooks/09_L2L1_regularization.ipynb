{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN_YMTY3G4hS"
      },
      "source": [
        "# L2, L1正則化（CIFAR10を用いた物体認識）\n",
        "\n",
        "---\n",
        "## 目的\n",
        "畳み込みニューラルネットワーク (Convolutional Neural Network; CNN) を用いてCIFAR10データセットに対する物体認識を行う．\n",
        "その際，L2正則化，L1正則化を用いることで，認識性能がどのように変化するかを確認する．\n",
        "\n",
        "## 対応するチャプター\n",
        "* 7.1.1: L2パラメータ正則化\n",
        "* 7.1.2: L1正則化\n",
        "* 8.1.3: バッチアルゴリズムとミニバッチアルゴリズム\n",
        "* 8.3.1: 確率的勾配降下法\n",
        "* 9.1: 畳み込み処理\n",
        "* 9.3: プーリング\n",
        "\n",
        "\n",
        "## モジュールのインポート\n",
        "プログラムの実行に必要なモジュールをインポートします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFodqtkEG4hU"
      },
      "outputs": [],
      "source": [
        "# モジュールのインポート\n",
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E2t0-OAG4hV"
      },
      "source": [
        "## GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`Use CUDA: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drjNhqyaG4hV"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpybcseLG4hV"
      },
      "source": [
        "## データセットの読み込み\n",
        "CIFAR10データセットを読み込みます．\n",
        "\n",
        "読み込んだ学習データのサイズを確認します．\n",
        "学習データは5万枚，1つのデータサイズは3x32x32の画像のような形式となっています．\n",
        "これは32x32ピクセルのカラー画像という意味になります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N06IwKRTG4hW"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ここでは，畳み込み層2層，全結合層3層から構成されるネットワークとします．\n",
        "\n",
        "1層目の畳み込み層は入力チャンネル数が1，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．\n",
        "2層目の畳み込み層は入力チャネル数が16，出力する特徴マップ数が32，畳み込むフィルタサイズは同じく3x3です．\n",
        "1つ目の全結合層は入力ユニット数は特徴マップのサイズから，`8*8*32`とし，出力は1024としています．\n",
        "次の全結合層入力，出力共に1024，出力層は入力が1024，出力が10です．\n",
        "また，ネットワーク内で使用する活性化関数を`self.act`に，プーリングを`self.pool`に設定します．\n",
        "これらの各層の構成を`__init__`関数で定義します．\n",
        "\n",
        "次に，`forward`関数では，定義した層を接続して処理するように記述します．\n",
        "`forward`関数の引数`x`は入力データです．\n",
        "それを`__init__`関数で定義した`conv1`に与え，その出力を活性化関数である`act`関数に与えます．\n",
        "そして，その出力を`pool`に入力して，プーリング処理結果を`h`として出力します．\n",
        "`h`は`conv2`に与えられて畳み込み処理とプーリング処理を行います．\n",
        "そして，出力`h`を`l1`に与えて全結合層の処理を行います．\n",
        "最終的に`l3`の全結合層の処理を行った出力`h`を戻り値としています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "        self.act = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.act(self.conv1(x)))\n",
        "        h = self.pool(self.act(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.act(self.l1(h))\n",
        "        h = self.act(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 正則化無しの学習\n",
        "\n",
        "L1, L2正則化の効果を確認するために，正則化を用いない素朴なネットワークの学習を行います．"
      ],
      "metadata": {
        "id": "22-D7ktWVzy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習\n",
        "\n",
        "１回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を30とします．\n",
        "\n",
        "学習を始める前に，`model.train()`を実行することで，ネットワークの演算を学習モードへ変更します．\n",
        "学習モードへ変更することで，ネットワーク内の演算のうち，学習とテストで挙動が変化する演算を一括で変更することが可能です．\n",
        "\n",
        "各更新において，学習用データと教師データをそれぞれ`image`と`label`とします．\n",
        "学習モデルにimageを与えて各クラスの確率yを取得します．\n",
        "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "そして，誤差をbackward関数で逆伝播し， step関数でネットワークの更新を行います．"
      ],
      "metadata": {
        "id": "cKs8ts6DV0DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model_naive = CNN()\n",
        "if use_cuda:\n",
        "    model_naive.cuda()\n",
        "\n",
        "optimizer_naive = torch.optim.SGD(model_naive.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 30\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model_naive.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_naive(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model_naive.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_naive.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ],
      "metadata": {
        "id": "krvAw1rjV0Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ],
      "metadata": {
        "id": "U-0QM8suV5zU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model_naive.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_naive(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / len(test_data)))"
      ],
      "metadata": {
        "id": "3ctbQydSV57E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ネットワークパラメータの可視化\n",
        "\n",
        "学習で獲得したネットワークモデルの重み（パラメータ）をグラフで可視化します．\n",
        "複数の層の重みがありますが，ここでは出力層（`l3`）の重みを可視化します．\n",
        "\n",
        "まず学習したモデル `model_naive` の出力層 `l3` の重み `weight` を抽出し，`weight_naive_l3` に保存します．\n",
        "この時，GPUを用いて学習した場合は，重みの行列（Tensor）を`cpu()`でCPUメモリ上へ移動したのちにNumpy配列に変換して保存します．\n",
        "\n",
        "その後，matplotlibの棒グラフプロット（`bar()`）を用いて重みの値を可視化します．"
      ],
      "metadata": {
        "id": "o0kthmv2V6R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 出力層の重みの抽出\n",
        "if use_cuda:\n",
        "    weight_naive_l3 = model_naive.l3.weight.data.cpu().numpy().flatten()\n",
        "else:\n",
        "    weight_naive_l3 = model_naive.l3.weight.data.numpy().flatten()\n",
        "\n",
        "plt.bar(range(weight_naive_l3.shape[0]), weight_naive_l3.flatten())\n",
        "plt.xlabel(\"weight index\")\n",
        "plt.ylabel(\"weight value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o7nf-zugV6al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqXb5xjdG4hX"
      },
      "source": [
        "---\n",
        "## L1 正則化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "\n",
        "### 学習\n",
        "\n",
        "L1正則化を導入して学習を行います．\n",
        "L1正則化以外のパラメータなどについては上記の正則化を導入しない場合の学習と同じ設定で行います．\n",
        "\n",
        "まず，L1正則化の度合いを制御するためのパラメータ`lam`を設定します．\n",
        "\n",
        "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "その分類結果に対する誤差に加えて，ネットワークパラメータのL1ノルムを計算し，損失関数に加えます．\n",
        "このようにすることで，学習時の重みの更新にL1正則化を行うことが可能となります．\n",
        "そして，誤差をbackward関数で逆伝播し， step関数でネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68RE3RTa76-W"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model_l1 = CNN()\n",
        "if use_cuda:\n",
        "    model_l1.cuda()\n",
        "\n",
        "optimizer_l1 = torch.optim.SGD(model_l1.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 30\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# 正則化のスケールパラメータ\n",
        "lam = 1e-4\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model_l1.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l1(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        # パラメータのL1ノルムを損失関数に足す\n",
        "        l1_loss = torch.tensor(0., requires_grad=True)\n",
        "        for w in model_l1.parameters():\n",
        "            l1_loss = l1_loss + torch.norm(w, 1)\n",
        "        loss = loss + lam * l1_loss\n",
        "        \n",
        "        model_l1.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_l1.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "### テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoYVMRGLzm1I"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model_l1.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l1(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / len(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ネットワークパラメータの可視化\n",
        "\n",
        "L1正則化を導入した学習で獲得したネットワークモデルの重み（パラメータ）をグラフで可視化します．\n",
        "ここでは出力層（`l3`）の重みを可視化します．\n",
        "\n",
        "L1正則化を適用して学習した場合には，多くのネットワークパラメータが0付近の値となり疎（スパース）になっていることがわかります．"
      ],
      "metadata": {
        "id": "H1aXu1ZeJr19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 出力層の重みの抽出\n",
        "if use_cuda:\n",
        "    weight_l1_l3 = model_l1.l3.weight.data.cpu().numpy().flatten()\n",
        "else:\n",
        "    weight_l1_l3 = model_l1.l3.weight.data.numpy().flatten()\n",
        "\n",
        "plt.bar(range(weight_l1_l3.shape[0]), weight_l1_l3.flatten())\n",
        "plt.xlabel(\"weight index\")\n",
        "plt.ylabel(\"weight value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4N_5ffEcNyoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqB1l1oG4hZ"
      },
      "source": [
        "---\n",
        "## L2正則化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNTVJoA_G4hZ"
      },
      "source": [
        "### 学習\n",
        "\n",
        "次にL2正則化を用いた学習を行います．\n",
        "\n",
        "まず，上のL1正則化と同様に，ネットワークモデルを初期化し，最適化手法，誤差関数などを設定します．\n",
        "\n",
        "L2正則化では、通常の誤差に加えて，各パラメータのL2ノルムを足し合わせることで，正則化を行うことができます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKkqtmURG4hZ"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model_l2 = CNN()\n",
        "if use_cuda:\n",
        "    model_l2.cuda()\n",
        "\n",
        "optimizer_l2 = torch.optim.SGD(model_l2.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 30\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# 正則化のスケールパラメータ\n",
        "lam = 1e-3\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model_l2.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l2(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        # パラメータのL2ノルムの二乗を損失関数に足す\n",
        "        l2_loss = torch.tensor(0., requires_grad=True)\n",
        "        for w in model_l2.parameters():\n",
        "            l2_loss = l2_loss + torch.norm(w)**2\n",
        "        loss = loss + lam * l2_loss\n",
        "        \n",
        "        model_l2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_l2.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL5tnUj5G4ha"
      },
      "source": [
        "### テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIQTsP90G4ha"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model_l2.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l2(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ネットワークパラメータの可視化\n",
        "\n",
        "L2正則化を導入した学習で獲得したネットワークモデルの重み（パラメータ）をグラフで可視化します．\n",
        "ここでは出力層（`l3`）の重みを可視化します．\n",
        "\n",
        "L2正則化を適用して学習した場合には，正則化を導入しない場合の重みと比べて，値が小さくなっていることがわかります．"
      ],
      "metadata": {
        "id": "iUmLdfn5YrSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 出力層の重みの抽出\n",
        "if use_cuda:\n",
        "    weight_l2_l3 = model_l2.l3.weight.data.cpu().numpy().flatten()\n",
        "else:\n",
        "    weight_l2_l3 = model_l2.l3.weight.data.numpy().flatten()\n",
        "\n",
        "plt.bar(range(weight_l2_l3.shape[0]), weight_l2_l3.flatten())\n",
        "plt.xlabel(\"weight index\")\n",
        "plt.ylabel(\"weight value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zNYQ5wu-YraQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcdQyCxSG4ha"
      },
      "source": [
        "### その他のL2正則化の方法\n",
        "\n",
        "PyTorchでは，optimizerの設定時に，`weight_decay=***`を設定することで，L2正則化を用いた学習を行うことが可能となります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU4-hJV9G4ha"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル\n",
        "model_l2_wd = CNN()\n",
        "if use_cuda:\n",
        "    model_l2_wd.cuda()\n",
        "\n",
        "# 最適化手法の設定（weight_decayでL2正則化を導入）\n",
        "optimizer = torch.optim.SGD(model_l2_wd.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# 学習 =========================================\n",
        "# ネットワークを学習モードへ変更\n",
        "model_l2_wd.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l2_wd(image)\n",
        "        \n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model_l2_wd.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))\n",
        "\n",
        "# テスト =======================================\n",
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model_l2_wd.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model_l2_wd(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUclIrLUG4ha"
      },
      "source": [
        "## 課題\n",
        "1. 正則化の違いや有無で認識性能の変化を確認しましょう"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "09_L2L1_regularization.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}