{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAjTgCq0e_M0"
      },
      "source": [
        "# データ集合の拡張（CIFAR10を用いた物体認識）\n",
        "\n",
        "---\n",
        "## 目的\n",
        "畳み込みニューラルネットワーク (Convolutional Neural Network; CNN) を用いてCIFAR10データセットに対する物体認識を行う．\n",
        "その際，データ集合の拡張（Data Augmentation）を行うことで認識性能がどのように変化するかを確認する．\n",
        "\n",
        "## モジュールのインポート\n",
        "プログラムの実行に必要なモジュールをインポートします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrihZLb_e_M3"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jafYcMcve_M4"
      },
      "source": [
        "## GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`Use CUDA: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjRa3kS7e_M4"
      },
      "outputs": [],
      "source": [
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTtkjPvbe_M5"
      },
      "source": [
        "## データセットの読み込み\n",
        "CIFAR10データセットを読み込みます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqJxZHkYe_M5"
      },
      "outputs": [],
      "source": [
        "train_data = CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_data = CIFAR10(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ここでは，畳み込み層2層，全結合層3層から構成されるネットワークとします．\n",
        "以前の演習と同じネットワーク構造のため，詳細は割愛します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
        "        self.l2 = nn.Linear(1024, 1024)\n",
        "        self.l3 = nn.Linear(1024, 10)\n",
        "        self.act = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.pool(self.act(self.conv1(x)))\n",
        "        h = self.pool(self.act(self.conv2(h)))\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.act(self.l1(h))\n",
        "        h = self.act(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caZlM5Bfe_M7"
      },
      "source": [
        "---\n",
        "## 画像変換によるAugmentation\n",
        "\n",
        "Data Augmentationのための関数を作成します．\n",
        "\n",
        "\n",
        "PyTorchでは，代表的な画像処理（画像変換）によるData Augmentationは，torchvision.transformsとして利用することが可能です．\n",
        "このノートブックでは以下の4つを使用します．\n",
        "\n",
        "* ColorJitter: コントラストや明るさ，色調の変換\n",
        "* RandomCrop: 画像の矩形をランダムに切り取り\n",
        "* RandomHorizontalFlip: 画像をランダムに左右反転\n",
        "* RandomRotation: 画像をランダムに回転\n",
        "* GaussianNoise: 画像にガウシアンノイズを付与\n",
        "\n",
        "また，上記の画像変換に加えて，配列データの正規化と前処理を行うための`ToTensor`を使用します．\n",
        "* ToTensor: 画像データをPyTorchのTensorオブジェクトへ変換（Augmentationでは無いことに注意）\n",
        "\n",
        "\n",
        "### BrightnessとContrastの違い\n",
        "\n",
        "**Brightness（輝度）**とは？\n",
        "\n",
        "輝度は、画像全体の「明るさ」を制御します。すべてのピクセル値が同じ比率で調整され、全体の明るさが変わります。輝度を上げると、画像全体が明るく見え、逆に下げると暗く見えます。\n",
        "\n",
        "**Contrast（コントラスト）**とは？\n",
        "\n",
        "コントラストは、画像内の明暗の差を強調するものです。コントラストを操作すると、画像の明るい部分はより明るく、暗い部分はより暗くなり、影響が増幅されます。逆にコントラストを下げると、明るさの差が小さくなり、画像がより「平坦」に見えます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像変換の可視化\n",
        "\n",
        "まず，5つの画像変換がどのような変換を行うかを可視化して確認します．\n",
        "\n",
        "GaussianNoiseについては，torchvisionに実装されていないため，今回は下記のように自分でクラスを定義します．\n"
      ],
      "metadata": {
        "id": "koTds-1kfQE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=0.05):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # PIL ImageをTensorに変換\n",
        "        img_tensor = transforms.ToTensor()(img)\n",
        "\n",
        "        # Gaussian ノイズを加える\n",
        "        noise = torch.randn(img_tensor.size()) * self.std + self.mean\n",
        "        img_tensor = img_tensor + noise\n",
        "\n",
        "        # 値を0から1の範囲にクリップ（Tensorは[0, 1]範囲にある必要がある）\n",
        "        img_tensor = torch.clamp(img_tensor, 0., 1.)\n",
        "\n",
        "        # Tensorを再度PIL Imageに変換\n",
        "        return transforms.ToPILImage()(img_tensor)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std})'\n",
        "\n",
        "\n",
        "data_vis_coljitter_brightness = CIFAR10(root=\"./\", train=True, transform=transforms.ColorJitter(brightness=0.5), download=True)\n",
        "data_vis_coljitter_contrast = CIFAR10(root=\"./\", train=True, transform=transforms.ColorJitter(contrast=0.5), download=True)\n",
        "data_vis_crop = CIFAR10(root=\"./\", train=True, transform=transforms.RandomCrop(32, padding=4), download=True)\n",
        "data_vis_flip = CIFAR10(root=\"./\", train=True, transform=transforms.RandomHorizontalFlip(), download=True)\n",
        "data_vis_rotate = CIFAR10(root=\"./\", train=True, transform=transforms.RandomRotation(degrees=(0, 90)), download=True)\n",
        "data_vis_gaussian = CIFAR10(root=\"./\", train=True, transform=GaussianNoise(mean=0., std=0.1), download=True)\n",
        "\n",
        "# Color Jitter (brightnessだけ) による変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_coljitter_brightness[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Color Jitter (brightness)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Color Jitter (contrastだけ) による変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_coljitter_contrast[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Color Jitter (contrast)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# RandomCropによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_crop[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Random Crop\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Random Horizontal Flipによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_flip[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Random Horizontal Flip\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Random Rotationによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_rotate[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Random Rotation\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gaussian Noiseによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_gaussian[0][0])\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Gaussian Noise\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zI1lVjfXfQMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Composeを用いた複数の変換の組み合わせ\n",
        "\n",
        "上記で試した画像変換を用いて，学習データに対してAugmentationを適用します．\n",
        "このとき，`transforms.Compose`を使用することで，複数の処理を連続して処理して画像データを返すことが可能となります．\n",
        "Composeの引数として，処理を行いたい変換のクラスをリスト内に定義します．\n",
        "\n",
        "これらの処理をリストに定義し，Composeクラスへ与えることで，定義した処理をランダムに適用したデータを返すことが可能となります．"
      ],
      "metadata": {
        "id": "2vo_cgDfj2Qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkN9dZVP0KNY"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([transforms.ColorJitter(brightness=0.5, contrast=0.4, hue=0.3),\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(degrees=(0, 90)),\n",
        "                                      GaussianNoise(mean=0., std=0.1),\n",
        "                                      transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "### 学習\n",
        "\n",
        "上記で定義したData Augmentationを用いて学習を行います．\n",
        "\n",
        "Data Augmentaionを適用するために，CIFAR10データセットを読み込む際に，`transform_transformtrain`の引数に上で定義したComposeを設定します．\n",
        "このようにすることで，データの読み出し時に自動的に画像変換を行いデータを呼び出すことが可能となります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68RE3RTa76-W"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_data = CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for image, label in train_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_loss += loss.item()\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "### テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoYVMRGLzm1I"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkJyi00je_M9"
      },
      "source": [
        "---\n",
        "## RandomErasingによるAugmentation\n",
        "\n",
        "その他のAugmentationとして，Random Erasing [1] があります．\n",
        "\n",
        "Random Erasingは，画像の一部にランダムに矩形を設定しマスク処理を行うData Augmentationです．\n",
        "\n",
        "RandomErasingもtorchvision.transformsに実装されていますので，これを使用してその効果を確認します．\n",
        "\n",
        "![](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/02489e6c-9489-4e69-c7c1-7a02bf341c08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Erasingを適用した画像の可視化\n",
        "\n",
        "Random Erasingを適用した結果を可視化し，その効果を確認します．\n",
        "\n",
        "torchvisionに実装されているRandomErasingでは，torch.Tensor型の配列データに対する処理のみをサポートしています．\n",
        "そのため，Composeを使用し，ToTensorでTensor型配列に変換したのちにRandomErasingを適用する順番で定義します．\n"
      ],
      "metadata": {
        "id": "0Xocnf1ykyEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_erasing = transforms.Compose([transforms.ToTensor(),\n",
        "                                        transforms.RandomErasing()])\n",
        "data_vis_erasing = CIFAR10(root=\"./\", train=True, transform=transform_erasing, download=True)\n",
        "\n",
        "# Random Erasingによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_erasing[0][0].permute(1, 2, 0))\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Random Erasing\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUp95YzJk6oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiSK5Tf4e_M-"
      },
      "source": [
        "### 学習\n",
        "\n",
        "RandomErasing（`transform_erasing`）を用いてネットワークの学習を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_97Y_ZlEe_M-"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_data = CIFAR10(root=\"./\", train=True, transform=transform_erasing, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for image, label in train_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_loss += loss.item()\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC7CkFwZe_M_"
      },
      "source": [
        "### テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ul4e7Xe_M_"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSesDVle_M_"
      },
      "source": [
        "---\n",
        "## MixupによるAugmentation\n",
        "\n",
        "その他の近年提案された効果的なAugmentation手法として，Mixup [2] があります．\n",
        "\n",
        "Mixupは二つの画像とそのラベル$(x_i, y_i), (x_j, y_j)$を下の式に従い，一定の比率で設計保管することで，中間的なデータを作成する手法です．\n",
        "\n",
        "\n",
        "$$\\tilde{x} = \\lambda x_i + (1 - \\lambda) x_j$$\n",
        "$$\\tilde{y} = \\lambda y_i + (1 - \\lambda) y_j$$\n",
        "\n",
        "\n",
        "![](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/048f8b50-f277-7b60-e16b-99c67ae19873.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mixupを適用した画像の可視化\n",
        "\n",
        "Mixupを適用した結果を可視化し，その効果を確認します．\n",
        "\n",
        "学習データセット `train_data` とデータローダー `train_loader` を用意し，ランダムに学習用画像を10枚サンプリングします．\n",
        "その後，得られた10枚の画像の組み合わせをランダムに決定し，混合比率 `lam` に従って2枚の画像から中間的な画像を生成します．\n",
        "通常は比率をベータ分布に従い決定しますが，今回は目視で確認することができるよう，`lam = 0.5` に固定し，可視化を行います．\n",
        "\n",
        "結果より，2枚の画像が混合されたデータが作成できていることがわかります．"
      ],
      "metadata": {
        "id": "HC-S2cf2pLHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "\n",
        "for image, label in train_loader:\n",
        "    # mix up -------------------------------------------\n",
        "    b = image.size(0)\n",
        "\n",
        "    # 比率を0.5で固定（可視化用）\n",
        "    lam = 0.5\n",
        "    # ベータ分布に従って比率をサンプリングする場合\n",
        "    # lam = np.random.beta(1, 1)\n",
        "\n",
        "    rand_idx = torch.randperm(b)\n",
        "    image_rand = image[rand_idx]\n",
        "    mixed_image = lam * image + (1 - lam) * image_rand\n",
        "\n",
        "    onehot = torch.eye(10)[label]\n",
        "    onehot_rand = onehot[rand_idx]\n",
        "    mixed_label = lam * onehot + (1 - lam) * onehot_rand\n",
        "    # --------------------------------------------------\n",
        "\n",
        "    # Mixupによる変換例\n",
        "    plt.clf()\n",
        "    fig = plt.figure(figsize=(12, 2.0))\n",
        "    for i in range(10):\n",
        "        ax = fig.add_subplot(1, 10, i + 1)\n",
        "        ax.imshow(image[i].permute(1, 2, 0))\n",
        "        ax.set_axis_off()\n",
        "    fig.suptitle(\"image 1\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.clf()\n",
        "    fig = plt.figure(figsize=(12, 2.0))\n",
        "    for i in range(10):\n",
        "        ax = fig.add_subplot(1, 10, i + 1)\n",
        "        ax.imshow(image_rand[i].permute(1, 2, 0))\n",
        "        ax.set_axis_off()\n",
        "    fig.suptitle(\"image 2\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.clf()\n",
        "    fig = plt.figure(figsize=(12, 2.0))\n",
        "    for i in range(10):\n",
        "        ax = fig.add_subplot(1, 10, i + 1)\n",
        "        ax.imshow(mixed_image[i].permute(1, 2, 0))\n",
        "        ax.set_axis_off()\n",
        "    fig.suptitle(\"Mixup\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "lATqjUflpLOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-_7tVae_M_"
      },
      "source": [
        "### 学習\n",
        "\n",
        "Mixupを用いてネットワークの学習を行います．\n",
        "\n",
        "まず，ベータ分布からmixupの割合`lam`をサンプリングし決定します．\n",
        "\n",
        "そして，ミニバッチのサンプルを読み込んだのちに，ミニバッチ内の画像データの順番をランダムに入れ替えた`image_rand`を作成し，元の順番のミニバッチとの重みつき和を計算することでデータのmixupを行います．\n",
        "\n",
        "また，教師ラベルに対しても同様の処理を行います．\n",
        "この時，ラベルを一度one-hotベクトル表現のラベルに変換したのちに，そのベクトルの重みつき和を求めることで，ラベルのmixupをおこんばいます．\n",
        "\n",
        "lossの計算時は，クラスインデックスを引数に与える通常のクロスエントロピー誤差（`nn.CrossEntropyLoss()`）を使用することができないため，ネットワークの出力とベクトル表現のラベルからクロスエントロピーを手動で計算します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kb0MozBe_NA"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_data = CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for image, label in train_loader:\n",
        "\n",
        "        # mix up -------------------------------------------\n",
        "        b = image.size(0)\n",
        "        lam = np.random.beta(1, 1)\n",
        "\n",
        "        rand_idx = torch.randperm(b)\n",
        "        image_rand = image[rand_idx]\n",
        "        mixed_image = lam * image + (1 - lam) * image_rand\n",
        "\n",
        "        onehot = torch.eye(10)[label]\n",
        "        onehot_rand = onehot[rand_idx]\n",
        "        mixed_label = lam * onehot + (1 - lam) * onehot_rand\n",
        "        # --------------------------------------------------\n",
        "\n",
        "        if use_cuda:\n",
        "            mixed_image = mixed_image.cuda()\n",
        "            mixed_label = mixed_label.cuda()\n",
        "\n",
        "        y = model(mixed_image)\n",
        "\n",
        "        b, c = y.shape\n",
        "        log_softmax = torch.log_softmax(y, dim=1)\n",
        "        loss = - torch.sum(mixed_label * log_softmax) / b\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_loss += loss.item()\n",
        "\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time :{}\".format(epoch, sum_loss / n_iter, time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ4VDO0Je_NA"
      },
      "source": [
        "### テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psJEdk9be_NA"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandAugmentによるAugmentation\n",
        "\n",
        "RandAugmentは、他の拡張技術（AutoAugmentなど）と異なり、特定のデータセットに依存せず、固定の数の変換操作をランダムに適用するシンプルな手法です。以下の特徴があります：\n",
        "\n",
        "1.\t操作の選択: いくつかの画像変換操作（回転、彩度調整、ズーム、コントラスト調整など）からランダムに選ばれます。\n",
        "2.\t操作の強度: 各操作に対して、一定の範囲でランダムに強度が設定されます。\n",
        "3.\tシンプルなハイパーパラメータ: 変換操作の数（N）と操作の強度（M）の2つのハイパーパラメータだけで調整可能です。\n",
        "\n",
        "RandAugmentの大きな利点は、少ない調整でさまざまなデータセットに対応できる点であり、手軽に使える強力なデータ拡張手法として知られています。\n",
        "\n",
        "![](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/bec5b056-bfcc-4fd9-c707-55e301aee07b.png)"
      ],
      "metadata": {
        "id": "ULpZLP6OLUh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandAugmentを適用した画像の可視化\n",
        "\n",
        "RandAugmentを適用した結果を可視化し，その効果を確認します．\n"
      ],
      "metadata": {
        "id": "__RwH-W8NDvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_randaugment = transforms.Compose([transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "                                            transforms.ToTensor()])\n",
        "data_vis_randaugment = CIFAR10(root=\"./\", train=True, transform=transform_randaugment, download=True)\n",
        "\n",
        "# Random Erasingによる変換例\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(12, 2.0))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    ax.imshow(data_vis_randaugment[0][0].permute(1, 2, 0))\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Random Erasing\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sDrS5l10NDvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptNfwqMwN--k"
      },
      "source": [
        "### 学習\n",
        "\n",
        "RandAugment（`transform_randaugment`）を用いてネットワークの学習を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp7_lN1NN--l"
      },
      "outputs": [],
      "source": [
        "# ネットワークモデル・最適化手法の設定\n",
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
        "batch_size = 64\n",
        "epoch_num = 10\n",
        "n_iter = len(train_data) / batch_size\n",
        "\n",
        "# データローダーの設定\n",
        "train_data = CIFAR10(root=\"./\", train=True, transform=transform_randaugment, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for image, label in train_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        loss = criterion(y, label)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_loss += loss.item()\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyz5MhusOMF4"
      },
      "source": [
        "### テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9JJwjWmOMF6"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / 10000.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNHz8-LSe_NA"
      },
      "source": [
        "## 課題\n",
        "1. 使用するAugmentationを変更して精度の変化を確認しましょう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbbRkYmGe_NA"
      },
      "source": [
        "## 参考文献\n",
        "1. Z. Zhong, et al., \"Random Erasing Data Augmentation,\" in AAAI, 2020.\n",
        "2. H. Zhang, et al., \"mixup: BEYOND EMPIRICAL RISK MINIMIZATION,\" in ICLR, 2018."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "10_data_augmentation.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}